# assumes the first column contains the assembly name
assemblies_path: "config/assemblies.tsv"

# Intervals from fasta file used for training:
# - "all": all positions
# - "defined": positions with defined nucleotides (not N)
# - "annotation_{feature}": only <feature> positions from annotation, e.g. CDS, exon
# - "balanced_v1": recipe used in original paper
target_intervals: "all"

window_size: 512
step_size: 256
add_rc: False  # random rc is now done on-the-fly during training

# chroms will be randomly assigned to splits
split_proportion:
  train: 0.99
  validation: 0.005
  test: 0.005

# this chroms are forced to be in validation set
whitelist_validation_chroms:
- "J01"            
- "J02"            
- "J03"            
- "J04"            
- "J05"            
- "J06"            
- "J07"             
  
# this chroms are forced to be in test set
whitelist_test_chroms:
- "S01"            
- "S02"            
- "S03"            
- "S04"            
- "S05"            
- "S06"            
- "S07"             

# We want to split data into shards of e.g. ~100MB each
# It's good to have at least num_cpus shards to increase parallel loading speed
# of iterable datasets from HF hub
samples_per_file: 500_000 

slurm:
  nodes: 1
  cpus_per_task: 16
  gpus: 16
  constraint: gpu
  queue: regular
  account: m342
  job_name: tiberius_gpu
  mail_user: nberkowitz@lbl.gov
  mail_type: ALL
  time: "24:00:00"